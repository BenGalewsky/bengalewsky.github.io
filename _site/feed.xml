<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ben Galewsky</title>
    <description>&lt;h1&gt;Development Blog&lt;/h1&gt;&lt;h3&gt;Research Programmer NCSA&lt;/h3&gt;</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 20 Dec 2018 09:57:57 -0600</pubDate>
    <lastBuildDate>Thu, 20 Dec 2018 09:57:57 -0600</lastBuildDate>
    <generator>Jekyll v3.7.4</generator>
    
      <item>
        <title>Building Tensorflow Docker Image for Openstack</title>
        <description>&lt;p&gt;With the many layers of virtualization, it’s easy to forget that docker images
ultimately run on a real CPU with its own architecture and characteristics. This
is usually not an issue, except when the code in the image makes assumptions about
that CPU. The Tensorflow library makes use of whatever hardware acceleration
is available. It is quite sensitive to the hardware the image is built on.&lt;/p&gt;

&lt;p&gt;I discovered this when trying to deploy a colleague’s Tensorflow application on
our OpenStack cluster. I was using the &lt;code class=&quot;highlighter-rouge&quot;&gt;tensorflow/tensorflow&lt;/code&gt; Docker image.
When I attempted to run it, it simply printed out the error:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Illegal instruction     (core dumped) python3 ./${MAIN_SCRIPT}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is caused by the standard images being built to take advantage of the AVX2 instruction
set. Since Tensorflow 1.6 the pre-built binaries assume the CPU supports those instructions.&lt;/p&gt;

&lt;p&gt;This post describes how I compiled Tensorflow for the specific hardware backing
our OpenStack and deployed my application via docker.&lt;/p&gt;

&lt;h1 id=&quot;build-tensorflow-locally&quot;&gt;Build Tensorflow Locally&lt;/h1&gt;
&lt;p&gt;Tensorflow is a big and complicated system. Compiling it depends on a large number
of dependencies and specialized build tools. Fortunately, the community has created a handy 
dockerized process to help with this build.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create a VM on the OpenStack cluster. I used an Ubuntu 16.0.2 image.&lt;/li&gt;
  &lt;li&gt;Install:
    &lt;ul&gt;
      &lt;li&gt;git&lt;/li&gt;
      &lt;li&gt;docker&lt;/li&gt;
      &lt;li&gt;docker-compose&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Make sure the ubuntu user has
&lt;a href=&quot;https://docs.docker.com/install/linux/linux-postinstall/#manage-docker-as-a-non-root-user&quot;&gt;permission to run docker commands&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Log into the VM and checkout a copy of my fork of Hadrian Mary’s &lt;a href=&quot;https://github.com/BenGalewsky/docker-tensorflow-builder&quot;&gt;tensorflow-builder&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;For now use my &lt;code class=&quot;highlighter-rouge&quot;&gt;ncsa_openstack&lt;/code&gt; branch. &lt;a href=&quot;https://github.com/hadim/docker-tensorflow-builder/pull/13&quot;&gt;Pull Request&lt;/a&gt; is in progress&lt;/li&gt;
  &lt;li&gt;As per the &lt;a href=&quot;https://github.com/hadim/docker-tensorflow-builder/blob/master/README.md&quot;&gt;README&lt;/a&gt;…&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;tensorflow/ubuntu-16.04/

&lt;span class=&quot;c&quot;&gt;# Build the Docker image&lt;/span&gt;
docker-compose build

&lt;span class=&quot;c&quot;&gt;# Set env variables&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PYTHON_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.5
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TF_VERSION_GIT_TAG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;v1.9.0
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;USE_GPU&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0

&lt;span class=&quot;c&quot;&gt;# Start the compilation&lt;/span&gt;
docker-compose run tf

&lt;span class=&quot;c&quot;&gt;# You can also do:&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# docker-compose run tf bash&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# bash build.sh&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Wait, wait, and wait some more… It’s a very long build time!&lt;/li&gt;
  &lt;li&gt;The wheel file for your architecture is sitting in the repositories wheels/ folder&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;create-a-docker-image&quot;&gt;Create a Docker Image&lt;/h1&gt;
&lt;p&gt;As a final step, I created a Dockerfile based on a Python image which installs the Tensorflow wheel:&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; python:3.5-stretch&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; tensorflow-1.9.0-cp35-cp35m-linux_x86_64.whl /&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN  &lt;/span&gt;pip install /tensorflow-1.9.0-cp35-cp35m-linux_x86_64.whl
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [&quot;python3&quot;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 10 Dec 2018 10:31:43 -0600</pubDate>
        <link>http://localhost:4000/openstack/docker/2018/12/10/BuildingTensorFlowForOpenstack1.html</link>
        <guid isPermaLink="true">http://localhost:4000/openstack/docker/2018/12/10/BuildingTensorFlowForOpenstack1.html</guid>
        
        
        <category>openstack</category>
        
        <category>docker</category>
        
      </item>
    
  </channel>
</rss>
